{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdbe7a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"C:/spark/spark-3.5.1-bin-hadoop3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b3d014",
   "metadata": {},
   "source": [
    "# Spark Context & Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e546c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.ml.feature import Binarizer\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76642d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few things we need to do before Spark can accept the data!\n",
    "# It needs to be in the form of two columns\n",
    "# (\"label\",\"features\")\n",
    "\n",
    "# Import VectorAssembler and Vectors\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01ff2c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "SparkContext.setSystemProperty('spark.hadoop.dfs.client.use.datanode.hostname', 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18b40235",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master=\"local\", appName=\"New Spark Context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e47970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://PhDLinh:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>New Spark Context</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=New Spark Context>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2920dcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- price_min: double (nullable = true)\n",
      " |-- price_max: double (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- mileage: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- engine_capacity: string (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- warranty: string (nullable = true)\n",
      " |-- weight: string (nullable = true)\n",
      " |-- href: string (nullable = true)\n",
      " |-- years_used: string (nullable = true)\n",
      "\n",
      "+--------------------+---------+---------+--------------------+--------------------+--------------------+-------+---------+------+-------+----------+--------+---------------+-------------+-------------+-------+--------------------+----------+\n",
      "|               title|    price|price_min|           price_max|            location|         description|  brand|    model|  year|mileage| condition|category|engine_capacity|       origin|     warranty| weight|                href|years_used|\n",
      "+--------------------+---------+---------+--------------------+--------------------+--------------------+-------+---------+------+-------+----------+--------+---------------+-------------+-------------+-------+--------------------+----------+\n",
      "|CC Vision Th·ªÉ Tha...|    3.7E7|    2.8E7|             3.286E7|Ph∆∞·ªùng C·∫ßu Kho, Q...|Ch√≠nh ch·ªß b√°n Vis...|  Honda|   Vision|2023.0|  12000|ƒê√£ s·ª≠ d·ª•ng|  Tay ga|   100 - 175 cc|ƒêang c·∫≠p nh·∫≠t|B·∫£o h√†nh h√£ng|> 50 kg|https://xe.chotot...|       2.0|\n",
      "|Vespa Sprint 2019...|    4.5E7|   4.31E7|              5.06E7|Ph∆∞·ªùng B·∫øn Ngh√©, ...|XE CAÃÅ NH√ÇN BAÃÅN ...|Piaggio|    Vespa|2019.0|  60000|ƒê√£ s·ª≠ d·ª•ng|  Tay ga|   100 - 175 cc|ƒêang c·∫≠p nh·∫≠t|B·∫£o h√†nh h√£ng|> 50 kg|https://xe.chotot...|       6.0|\n",
      "|Xe tay ga Yamaha ...|    2.3E7|  1.702E7|             1.998E7|Ph∆∞·ªùng T√¢n ƒê·ªãnh, ...|üõµ Th√¥ng tin xe: ...| Yamaha|    Latte|2021.0|  24000|ƒê√£ s·ª≠ d·ª•ng|  Tay ga|   100 - 175 cc|     Nh·∫≠t B·∫£n|B·∫£o h√†nh h√£ng|> 50 kg|https://xe.chotot...|       4.0|\n",
      "|Xe hoc sinh di ho...|7500000.0|7730000.0|           9080000.0|Ph∆∞·ªùng T√¢n ƒê·ªãnh, ...|Xe cup 50cc kh√¥ng...|    SYM|  Elegant|2018.0|  25000|ƒê√£ s·ª≠ d·ª•ng|   Xe s·ªë|     D∆∞·ªõi 50 cc|ƒêang c·∫≠p nh·∫≠t|B·∫£o h√†nh h√£ng|> 50 kg|https://xe.chotot...|       7.0|\n",
      "|   xe Air Blade 2013|    1.6E7|  1.383E7|1.6239999999999998E7|Ph∆∞·ªùng Nguy·ªÖn C∆∞ ...|Xe Air Blade 2013...|  Honda|Air Blade|2013.0|  80000|ƒê√£ s·ª≠ d·ª•ng|  Tay ga|   100 - 175 cc|     Vi·ªát Nam|B·∫£o h√†nh h√£ng|> 50 kg|https://xe.chotot...|      12.0|\n",
      "+--------------------+---------+---------+--------------------+--------------------+--------------------+-------+---------+------+-------+----------+--------+---------------+-------------+-------------+-------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"motorbike_price_prediction\").getOrCreate()\n",
    "\n",
    "# ƒê·ªçc file CSV (ƒë·ªïi ƒë∆∞·ªùng d·∫´n cho ƒë√∫ng)\n",
    "path = r\"D:/DATA_SCIENCE_KHTN/mon_7/project_1/motorbike_cleaned.csv\"\n",
    "data = spark.read.csv(path, header=True, inferSchema=True)\n",
    "\n",
    "data.printSchema()\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6d33826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+---------+--------------------+-----------+\n",
      "|brand   |model    |price_min|price    |price_max           |price_fixed|\n",
      "+--------+---------+---------+---------+--------------------+-----------+\n",
      "|Honda   |Vision   |2.8E7    |3.7E7    |3.286E7             |3.043E7    |\n",
      "|Piaggio |Vespa    |4.31E7   |4.5E7    |5.06E7              |4.5E7      |\n",
      "|Yamaha  |Latte    |1.702E7  |2.3E7    |1.998E7             |1.85E7     |\n",
      "|SYM     |Elegant  |7730000.0|7500000.0|9080000.0           |8405000.0  |\n",
      "|Honda   |Air Blade|1.383E7  |1.6E7    |1.6239999999999998E7|1.6E7      |\n",
      "|Honda   |Wave     |1.008E7  |7300000.0|1.183E7             |1.0955E7   |\n",
      "|Yamaha  |Sirius   |6970000.0|7500000.0|8189999.999999999   |7500000.0  |\n",
      "|Honda   |Lead     |2.745E7  |3.3E7    |3.222E7             |2.9835E7   |\n",
      "|Kawasaki|D√≤ng kh√°c|2.208E7  |1.99E7   |2.592E7             |2.4E7      |\n",
      "|SYM     |Wolf     |1.362E7  |1.48E7   |1.598E7             |1.48E7     |\n",
      "+--------+---------+---------+---------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# T·∫°o c·ªôt mid_price\n",
    "data = data.withColumn(\"mid_price\", (col(\"price_min\") + col(\"price_max\")) / 2)\n",
    "\n",
    "# Thay gi√° ngo√†i kho·∫£ng b·∫±ng mid-point\n",
    "data = data.withColumn(\n",
    "    \"price_fixed\",\n",
    "    when((col(\"price\") < col(\"price_min\")) | (col(\"price\") > col(\"price_max\")), col(\"mid_price\"))\n",
    "    .otherwise(col(\"price\"))\n",
    ")\n",
    "\n",
    "# Ki·ªÉm tra k·∫øt qu·∫£\n",
    "data.select(\"brand\", \"model\", \"price_min\", \"price\", \"price_max\", \"price_fixed\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89c457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn(\n",
    "    \"price\",\n",
    "    when((col(\"price\") < col(\"price_min\")) | (col(\"price\") > col(\"price_max\")), (col(\"price_min\") + col(\"price_max\")) / 2)\n",
    "    .otherwise(col(\"price\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a180677b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric cols: ['price', 'price_min', 'price_max', 'mid_price', 'price_fixed']\n",
      "String  cols: ['title', 'location', 'description', 'brand', 'model', 'year', 'mileage', 'condition', 'category', 'engine_capacity', 'origin', 'warranty', 'weight', 'href', 'years_used']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType, IntegerType, LongType, FloatType, ShortType, DecimalType, StringType\n",
    "\n",
    "numeric_types = (DoubleType, IntegerType, LongType, FloatType, ShortType, DecimalType)\n",
    "numeric_cols  = [f.name for f in data.schema.fields if isinstance(f.dataType, numeric_types)]\n",
    "string_cols   = [f.name for f in data.schema.fields if isinstance(f.dataType, StringType)]\n",
    "\n",
    "print(\"Numeric cols:\", numeric_cols)\n",
    "print(\"String  cols:\", string_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "252e028c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+--------------------+--------------------+------------------+\n",
      "|summary|price             |price_min           |price_max           |mid_price           |price_fixed       |\n",
      "+-------+------------------+--------------------+--------------------+--------------------+------------------+\n",
      "|count  |5807              |5807                |5807                |5807                |5807              |\n",
      "|mean   |1.85821084422249E7|1.707582917168934E7 |2.005503271913208E7 |1.856543094541071E7 |1.85821084422249E7|\n",
      "|stddev |1.30708173654532E7|1.1993024759570112E7|1.4090642381696567E7|1.3038490015451137E7|1.30708173654532E7|\n",
      "|min    |1335000.0         |1230000.0           |1440000.0           |1335000.0           |1335000.0         |\n",
      "|max    |6.8E7             |5.873E7             |6.895E7             |6.384E7             |6.8E7             |\n",
      "+-------+------------------+--------------------+--------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark describe: count, mean, stddev, min, max\n",
    "data.select(*numeric_cols).describe().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b238a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------+------------+\n",
      "|model    |model_idx|category|category_idx|\n",
      "+---------+---------+--------+------------+\n",
      "|Vision   |4.0      |Tay ga  |0.0         |\n",
      "|Vespa    |10.0     |Tay ga  |0.0         |\n",
      "|Latte    |135.0    |Tay ga  |0.0         |\n",
      "|Elegant  |46.0     |Xe s·ªë   |1.0         |\n",
      "|Air Blade|1.0      |Tay ga  |0.0         |\n",
      "+---------+---------+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "cat_cols = [\"model\", \"category\"]\n",
    "\n",
    "# 1) Xo√° c·ªôt *_idx c≈© n·∫øu ƒë√£ t·ªìn t·∫°i (tr√°nh l·ªói khi rerun cell)\n",
    "to_drop = [f\"{c}_idx\" for c in cat_cols if f\"{c}_idx\" in data.columns]\n",
    "if to_drop:\n",
    "    data = data.drop(*to_drop)\n",
    "\n",
    "# 2) Index tu·∫ßn t·ª± t·ª´ng c·ªôt (v·∫´n l√† for, kh√¥ng pipeline)\n",
    "for c in cat_cols:\n",
    "    out_col = f\"{c}_idx\"\n",
    "    # N·∫øu mu·ªën an to√†n th√™m, ch·ªâ t·∫°o khi ch∆∞a c√≥\n",
    "    if out_col not in data.columns:\n",
    "        indexer = StringIndexer(inputCol=c, outputCol=out_col, handleInvalid=\"keep\")\n",
    "        data = indexer.fit(data).transform(data)\n",
    "\n",
    "data.select(\"model\", \"model_idx\", \"category\", \"category_idx\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e275873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    inputCols=[f\"{c}_idx\" for c in cat_cols],\n",
    "    outputCols=[f\"{c}_vec\" for c in cat_cols],\n",
    "    dropLast=True\n",
    ")\n",
    "\n",
    "data_encoded = encoder.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6c87565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------+--------+------------+-------------+\n",
      "|model    |model_idx|model_vec        |category|category_idx|category_vec |\n",
      "+---------+---------+-----------------+--------+------------+-------------+\n",
      "|Vision   |4.0      |(162,[4],[1.0])  |Tay ga  |0.0         |(7,[0],[1.0])|\n",
      "|Vespa    |10.0     |(162,[10],[1.0]) |Tay ga  |0.0         |(7,[0],[1.0])|\n",
      "|Latte    |135.0    |(162,[135],[1.0])|Tay ga  |0.0         |(7,[0],[1.0])|\n",
      "|Elegant  |46.0     |(162,[46],[1.0]) |Xe s·ªë   |1.0         |(7,[1],[1.0])|\n",
      "|Air Blade|1.0      |(162,[1],[1.0])  |Tay ga  |0.0         |(7,[0],[1.0])|\n",
      "+---------+---------+-----------------+--------+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_encoded.select(\n",
    "    \n",
    "    \"model\", \"model_idx\", \"model_vec\",\n",
    "    \"category\", \"category_idx\", \"category_vec\"\n",
    ").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34cf40d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema BEFORE:\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- price_min: double (nullable = true)\n",
      " |-- price_max: double (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- mileage: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- engine_capacity: string (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- warranty: string (nullable = true)\n",
      " |-- weight: string (nullable = true)\n",
      " |-- href: string (nullable = true)\n",
      " |-- years_used: string (nullable = true)\n",
      " |-- mid_price: double (nullable = true)\n",
      " |-- price_fixed: double (nullable = true)\n",
      " |-- model_idx: double (nullable = false)\n",
      " |-- category_idx: double (nullable = false)\n",
      " |-- model_vec: vector (nullable = true)\n",
      " |-- category_vec: vector (nullable = true)\n",
      "\n",
      "\n",
      "Schema AFTER:\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- price_min: double (nullable = true)\n",
      " |-- price_max: double (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- model: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- mileage: double (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- engine_capacity: string (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- warranty: string (nullable = true)\n",
      " |-- weight: string (nullable = true)\n",
      " |-- href: string (nullable = true)\n",
      " |-- years_used: double (nullable = true)\n",
      " |-- mid_price: double (nullable = true)\n",
      " |-- price_fixed: double (nullable = true)\n",
      " |-- model_idx: double (nullable = false)\n",
      " |-- category_idx: double (nullable = false)\n",
      " |-- model_vec: vector (nullable = true)\n",
      " |-- category_vec: vector (nullable = true)\n",
      "\n",
      "+-------+----------+\n",
      "|mileage|years_used|\n",
      "+-------+----------+\n",
      "|12000.0|       2.0|\n",
      "|60000.0|       6.0|\n",
      "|24000.0|       4.0|\n",
      "|25000.0|       7.0|\n",
      "|80000.0|      12.0|\n",
      "+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# In schema tr∆∞·ªõc ƒë·ªÉ th·∫•y hi·ªán tr·∫°ng\n",
    "print(\"Schema BEFORE:\")\n",
    "data_encoded.printSchema()\n",
    "\n",
    "# √âp v·ªÅ double: b·ªè k√Ω t·ª± ngo√†i s·ªë, d·∫•u ch·∫•m v√† d·∫•u tr·ª´\n",
    "data_encoded = (\n",
    "    data_encoded\n",
    "    .withColumn(\"mileage\", F.regexp_replace(F.col(\"mileage\").cast(\"string\"), r\"[^0-9\\.\\-]\", \"\").cast(\"double\"))\n",
    "    .withColumn(\"years_used\", F.regexp_replace(F.col(\"years_used\").cast(\"string\"), r\"[^0-9\\.\\-]\", \"\").cast(\"double\"))\n",
    ")\n",
    "\n",
    "# (tu·ª≥ ch·ªçn) B·ªè d√≤ng thi·∫øu 2 c·ªôt n√†y n·∫øu c√≤n null\n",
    "data_encoded = data_encoded.dropna(subset=[\"mileage\", \"years_used\"])\n",
    "\n",
    "print(\"\\nSchema AFTER:\")\n",
    "data_encoded.printSchema()\n",
    "data_encoded.select(\"mileage\",\"years_used\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3974bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|features                                |\n",
      "+----------------------------------------+\n",
      "|(171,[0,1,6,164],[12000.0,2.0,1.0,1.0]) |\n",
      "|(171,[0,1,12,164],[60000.0,6.0,1.0,1.0])|\n",
      "+----------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------------+-------+---------+---------+--------------------+--------------------+-------+------+------+-------+----------+--------+---------------+-------------+-------------+-------+--------------------+----------+---------+-----------+---------+------------+----------------+-------------+--------------------+\n",
      "|               title|  price|price_min|price_max|            location|         description|  brand| model|  year|mileage| condition|category|engine_capacity|       origin|     warranty| weight|                href|years_used|mid_price|price_fixed|model_idx|category_idx|       model_vec| category_vec|            features|\n",
      "+--------------------+-------+---------+---------+--------------------+--------------------+-------+------+------+-------+----------+--------+---------------+-------------+-------------+-------+--------------------+----------+---------+-----------+---------+------------+----------------+-------------+--------------------+\n",
      "|CC Vision Th·ªÉ Tha...|3.043E7|    2.8E7|  3.286E7|Ph∆∞·ªùng C·∫ßu Kho, Q...|Ch√≠nh ch·ªß b√°n Vis...|  Honda|Vision|2023.0|12000.0|ƒê√£ s·ª≠ d·ª•ng|  Tay ga|   100 - 175 cc|ƒêang c·∫≠p nh·∫≠t|B·∫£o h√†nh h√£ng|> 50 kg|https://xe.chotot...|       2.0|  3.043E7|    3.043E7|      4.0|         0.0| (162,[4],[1.0])|(7,[0],[1.0])|(171,[0,1,6,164],...|\n",
      "|Vespa Sprint 2019...|  4.5E7|   4.31E7|   5.06E7|Ph∆∞·ªùng B·∫øn Ngh√©, ...|XE CAÃÅ NH√ÇN BAÃÅN ...|Piaggio| Vespa|2019.0|60000.0|ƒê√£ s·ª≠ d·ª•ng|  Tay ga|   100 - 175 cc|ƒêang c·∫≠p nh·∫≠t|B·∫£o h√†nh h√£ng|> 50 kg|https://xe.chotot...|       6.0|  4.685E7|      4.5E7|     10.0|         0.0|(162,[10],[1.0])|(7,[0],[1.0])|(171,[0,1,12,164]...|\n",
      "+--------------------+-------+---------+---------+--------------------+--------------------+-------+------+------+-------+----------+--------+---------------+-------------+-------------+-------+--------------------+----------+---------+-----------+---------+------------+----------------+-------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"mileage\", \"years_used\",  \"model_vec\", \"category_vec\"],\n",
    "    outputCol=\"features\"   # inputs\n",
    ")\n",
    "\n",
    "data_pre = assembler.transform(data_encoded)\n",
    "\n",
    "data_pre.select(\"features\").show(2, False)\n",
    "data_pre.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0714334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|               price|\n",
      "+-------+--------------------+\n",
      "|  count|                4148|\n",
      "|   mean|1.8319493541465767E7|\n",
      "| stddev| 1.276077357535034E7|\n",
      "|    min|           2000000.0|\n",
      "|    max|               6.7E7|\n",
      "+-------+--------------------+\n",
      "\n",
      "+-------+--------------------+\n",
      "|summary|               price|\n",
      "+-------+--------------------+\n",
      "|  count|                1654|\n",
      "|   mean|1.9261725824667472E7|\n",
      "| stddev|1.3800570962255662E7|\n",
      "|    min|           1335000.0|\n",
      "|    max|               6.8E7|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "final_data = data_pre.select(\"features\", F.col(\"price\").alias(\"price\"))\n",
    "\n",
    "train_data, test_data = final_data.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "train_data.describe().show()\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecf4528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "gbt = GBTRegressor(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"price\",\n",
    "    predictionCol=\"Predict_price\",\n",
    "    maxIter=150,       # 100‚Äì300 th∆∞·ªùng t·ªët\n",
    "    maxDepth=7,        # 5‚Äì9 tu·ª≥ d·ªØ li·ªáu\n",
    "    stepSize=0.1,      # learning rate\n",
    "    subsamplingRate=1.0,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21cceabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GBT fitted\n"
     ]
    }
   ],
   "source": [
    "gbt_model = gbt.fit(train_data)\n",
    "print(\"‚úÖ GBT fitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1bd03ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+--------------+----------------+\n",
      "|Predict_price_round|price_round|residual_round|pct_diff_%_round|\n",
      "+-------------------+-----------+--------------+----------------+\n",
      "|7925322.0          |6585000.0  |-1340322.0    |20.35           |\n",
      "|1.0719397E7        |1.13E7     |580603.0      |-5.14           |\n",
      "|7389920.0          |7370000.0  |-19920.0      |0.27            |\n",
      "|7389920.0          |7370000.0  |-19920.0      |0.27            |\n",
      "|1.0716023E7        |1.0955E7   |238977.0      |-2.18           |\n",
      "|9618645.0          |1.037E7    |751355.0      |-7.25           |\n",
      "|1.1122744E7        |1.113E7    |7256.0        |-0.07           |\n",
      "|7694862.0          |6455000.0  |-1239862.0    |19.21           |\n",
      "|7837239.0          |7355000.0  |-482239.0     |6.56            |\n",
      "|7694862.0          |6585000.0  |-1109862.0    |16.85           |\n",
      "+-------------------+-----------+--------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# D·ª± b√°o b·∫±ng m√¥ h√¨nh GBT\n",
    "gbt_pred = gbt_model.transform(test_data)\n",
    "\n",
    "# T√≠nh residual v√† % ch√™nh l·ªách\n",
    "gbt_pred = (\n",
    "    gbt_pred\n",
    "    .withColumn(\"residual\", F.col(\"price\") - F.col(\"Predict_price\"))\n",
    "    .withColumn(\n",
    "        \"pct_diff_%\", \n",
    "        F.when(\n",
    "            F.col(\"price\") != 0,\n",
    "            ((F.col(\"Predict_price\") - F.col(\"price\")) / F.col(\"price\")) * 100\n",
    "        ).otherwise(F.lit(None))\n",
    "    )\n",
    ")\n",
    "\n",
    "# L√†m tr√≤n cho d·ªÖ nh√¨n\n",
    "gbt_pred = (\n",
    "    gbt_pred\n",
    "    .withColumn(\"Predict_price_round\", F.round(\"Predict_price\", 0))\n",
    "    .withColumn(\"price_round\", F.round(\"price\", 0))\n",
    "    .withColumn(\"residual_round\", F.round(\"residual\", 0))\n",
    "    .withColumn(\"pct_diff_%_round\", F.round(\"pct_diff_%\", 2))\n",
    ")\n",
    "\n",
    "# Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "gbt_pred.select(\n",
    "    \"Predict_price_round\", \"price_round\", \"residual_round\", \"pct_diff_%_round\"\n",
    ").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cd146eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT RMSE: 4560312.803944209\n",
      "GBT MSE: 20796452869817.49\n",
      "GBT R2: 0.8907408522171143\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "for metric in [\"rmse\", \"mse\", \"r2\"]:\n",
    "    ev = RegressionEvaluator(labelCol=\"price\", predictionCol=\"Predict_price\", metricName=metric)\n",
    "    val = ev.evaluate(gbt_pred)\n",
    "    print(f\"GBT {metric.upper()}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5367fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
